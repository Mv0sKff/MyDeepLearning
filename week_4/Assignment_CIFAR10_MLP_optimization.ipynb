{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mv0sKff/MyDeepLearning/blob/main/week_4/Assignment_CIFAR10_MLP_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emh1lXeYaMVF"
      },
      "source": [
        "# CIFAR 10 with a MLP in PyTorch\n",
        "We return to our problem form last week and try to optimize our solution:\n",
        "* use TensorBoard to visualize the training\n",
        "* try different Losses\n",
        "* try different Optimizers\n",
        "* try different hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7enuKthZuFC",
        "outputId": "62a1b83e-7e01-43f6-d945-629ca4771b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "2rui6YPgaWHn"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ib9AeEvawaZ"
      },
      "source": [
        "## Get CIFAR\n",
        "Use PyTorch Data Loaders (more next week) to get data batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_5YooJWsadqw"
      },
      "outputs": [],
      "source": [
        "#transform input data (image) to tensor\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     transforms.Lambda(lambda x: x.view(-1)) # flatten\n",
        "])\n",
        "\n",
        "#set batch size\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "qSerMWeDa6UA",
        "outputId": "a00e7702-4e8b-4cc4-c8cb-508e935c5575"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bird  bird  horse car  \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter) #get data from loader!\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "cXvRBHIWbKdX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re0XcPj6daEj"
      },
      "source": [
        "## Assignment: design MLP to classify CIFAR10\n",
        "\n",
        "### E1 use TensorBoard to visualize the training\n",
        "\n",
        "### E2 try two different Losses\n",
        "\n",
        "### E3 try two different Optimizers\n",
        "* SGD with Momentum\n",
        "* AdaGrad or Adam\n",
        "\n",
        "### E4 implement a learning rate schedule\n",
        "* use SGD with Momentung as Optimizer\n",
        "* use a Multi-step schedule\n",
        "\n",
        "### Notes:\n",
        "* USE THE GPU! -> need to transfer the model and data to the GPU\n",
        "* MLP take 1D input - CIFAR imges are 2D -> first operator of your net needs to flatten the image\n",
        "* CIFAR is a multi class problem: use a SOFTMAX layer to output vector of class propabilities -> user argmax to get the class lable\n",
        "* Start small: use a small net with a reducet training set and a few epochs to test your setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "JnuW4X07h_ao"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "iHcYNEmIegDu"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_sizes, output_size):\n",
        "    super(MLP, self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
        "    layers.append(nn.ReLU())\n",
        "\n",
        "    for i in range(1, len(hidden_sizes)):\n",
        "        layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "    layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
        "    #layers.append(torch.nn.Softmax())\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 3072\n",
        "hidden_sizes = [512, 256]\n",
        "output_size = 1\n",
        "\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "model = MLP(input_size, hidden_sizes, output_size).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "iJ9Hbc5Jd2M2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "      images = images.view(images.size(0), -1)\n",
        "      labels = labels.view(-1, 1).float()\n",
        "\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()            # Clear gradients\n",
        "      outputs = model(images)           # Forward pass\n",
        "      loss = criterion(outputs, labels)  # Compute loss\n",
        "      loss.backward()                  # Backpropagation\n",
        "      optimizer.step()                 # Update weights\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9A_5e3zeHtc",
        "outputId": "1d721511-1404-4861-a805-6680c3b3666a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G26KHvBshyAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Assignment_CIFAR10_MLP_optimization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}